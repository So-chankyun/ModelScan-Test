{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Description\n",
    "- 우선 기능 단위로 만들고 하나의 모듈(클래스)로 만들어서 작동시켜보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from safetensors.torch import load_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert safetensors -> pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"/Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model\"\n",
    "\n",
    "ext_in = 'safetensors'\n",
    "ext_out = 'pkl'\n",
    "\n",
    "MODEL_NAME = \"Mistral-Nemo-Instruct-2407\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(ext_in:str,path:str):\n",
    "    tensors = None\n",
    "\n",
    "    if ext_in == 'safetensors':\n",
    "        print(\"execute load_file\")\n",
    "        tensors = load_file(path)\n",
    "    \n",
    "    return tensors\n",
    "\n",
    "def store_model(ext_out:str,path:str,tensors=None):\n",
    "    '''\n",
    "    tensor는 어떤 library를 사용하여 load 하는지에 따라 형식이 달라질 수 있다.\n",
    "    추후 다양한 type을 지원할 수 있도록 모듈을 생성해야할 것이다.\n",
    "\n",
    "    1. torch : collections.OrderedDict\n",
    "    '''\n",
    "    if ext_out == 'pkl':\n",
    "        # pickle을 사용하여 state_dict 저장\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(tensors, f)\n",
    "\n",
    "def convert(base_path:str,model_name:str,file_name:str,ext_in:str, ext_out:str):\n",
    "    # 1. load model weight with ext_in extension file\n",
    "    load_model_file_path = os.path.join(base_path,ext_in,model_name,file_name)\n",
    "    print(f\"Source Model File Path : {load_model_file_path}\")\n",
    "\n",
    "    # 각 확장자 별로 load함수를 달리 해야한다.\n",
    "    tensors = load_model(ext_in=ext_in,path=load_model_file_path)\n",
    "\n",
    "    # 2. store model weight with ext_out extension file\n",
    "    # .pkl 파일 경로 지정\n",
    "    store_model_file_name = '.'.join([file_name.split('.')[0],ext_out])\n",
    "    store_model_file_path = os.path.join(base_path,ext_out,model_name,store_model_file_name)\n",
    "    print(f\"Store File Model File Path : {store_model_file_path}\")\n",
    "    store_model(ext_out=ext_out,path=store_model_file_path,tensors=tensors)  \n",
    "\n",
    "def model_scan(base_path:str,model_name:str,file_name:str,ext_in:str, ext_out:str):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelScan():\n",
    "    def __init__(self,base_path:str,model_name:str,file_name:str,ext_in:str,ext_out:str):\n",
    "        self.base_path = base_path\n",
    "        self.model_name = model_name\n",
    "        self.file_name = file_name\n",
    "        self.ext_in = ext_in\n",
    "        self.ext_out = ext_out\n",
    "        self.tensors = []\n",
    "    \n",
    "    def load_model(self,path:str):\n",
    "        '''\n",
    "        다양한 extension input을 지원할 수 있도록 해야함.\n",
    "        '''\n",
    "        tensor = None\n",
    "\n",
    "        if self.ext_in == 'safetensors':\n",
    "            print(\"execute load_file\")\n",
    "            tensor = load_file(path)\n",
    "        \n",
    "        self.tensors.append(tensor)\n",
    "    \n",
    "    def store_model(ext_out:str,path:str,tensors=None):\n",
    "        '''\n",
    "        tensor는 어떤 library를 사용하여 load 하는지에 따라 형식이 달라질 수 있다.\n",
    "        추후 다양한 type을 지원할 수 있도록 모듈을 생성해야할 것이다.\n",
    "\n",
    "        1. torch : collections.OrderedDict\n",
    "        '''\n",
    "        if ext_out == 'pkl':\n",
    "            # pickle을 사용하여 state_dict 저장\n",
    "            with open(path, 'wb') as f:\n",
    "                pickle.dump(tensors, f)\n",
    "\n",
    "    def convert(self):\n",
    "        # 1. load model weight with ext_in extension file\n",
    "        load_model_file_path = os.path.join(self.base_path,self.ext_in,self.model_name,self.file_name)\n",
    "        print(f\"Source Model File Path : {load_model_file_path}\")\n",
    "\n",
    "        # 각 확장자 별로 load함수를 달리 해야한다.\n",
    "        tensors = load_model(ext_in=ext_in,path=load_model_file_path)\n",
    "\n",
    "        # 2. store model weight with ext_out extension file\n",
    "        # .pkl 파일 경로 지정\n",
    "        store_model_file_name = '.'.join([self.file_name.split('.')[0],self.ext_out])\n",
    "        store_model_file_path = os.path.join(self.base_path,ext_out,self.model_name,store_model_file_name)\n",
    "        print(f\"Store File Model File Path : {store_model_file_path}\")\n",
    "        store_model(ext_out=ext_out,path=store_model_file_path,tensors=tensors) \n",
    "    \n",
    "    def scan(self):\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model-00003-of-00005.safetensors',\n",
       " 'model-00002-of-00005.safetensors',\n",
       " 'model-00001-of-00005.safetensors',\n",
       " 'model-00004-of-00005.safetensors',\n",
       " 'model-00005-of-00005.safetensors']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file_list = os.listdir(os.path.join(BASE_PATH,ext_in,MODEL_NAME))\n",
    "model_weight_file_list = [fn for fn in model_file_list if fn.endswith('.safetensors') and not 'consolidated' in fn]\n",
    "model_weight_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/safetensors/Mistral-Nemo-Instruct-2407/model-00003-of-00005.safetensors\n",
      "execute load_file\n",
      "Store File Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/pkl/Mistral-Nemo-Instruct-2407/model-00003-of-00005.pkl\n",
      "Source Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/safetensors/Mistral-Nemo-Instruct-2407/model-00002-of-00005.safetensors\n",
      "execute load_file\n",
      "Store File Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/pkl/Mistral-Nemo-Instruct-2407/model-00002-of-00005.pkl\n",
      "Source Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/safetensors/Mistral-Nemo-Instruct-2407/model-00001-of-00005.safetensors\n",
      "execute load_file\n",
      "Store File Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/pkl/Mistral-Nemo-Instruct-2407/model-00001-of-00005.pkl\n",
      "Source Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/safetensors/Mistral-Nemo-Instruct-2407/model-00004-of-00005.safetensors\n",
      "execute load_file\n",
      "Store File Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/pkl/Mistral-Nemo-Instruct-2407/model-00004-of-00005.pkl\n",
      "Source Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/safetensors/Mistral-Nemo-Instruct-2407/model-00005-of-00005.safetensors\n",
      "execute load_file\n",
      "Store File Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/pkl/Mistral-Nemo-Instruct-2407/model-00005-of-00005.pkl\n"
     ]
    }
   ],
   "source": [
    "model_file_list = os.listdir(os.path.join(BASE_PATH,ext_in,MODEL_NAME))\n",
    "model_weight_file_list = [fn for fn in model_file_list if fn.endswith('.safetensors') and not 'consolidated' in fn]\n",
    "\n",
    "for weight in model_weight_file_list:\n",
    "    convert(base_path=BASE_PATH,model_name=MODEL_NAME,file_name=weight,ext_in=ext_in,ext_out=ext_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 파일 별 modelscan 수행.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelscan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
