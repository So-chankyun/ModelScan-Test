{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Description\n",
    "- 우선 기능 단위로 만들고 하나의 모듈(클래스)로 만들어서 작동시켜보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "from safetensors.torch import load_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Huggingface 모델 다운로드 로직 구성\n",
    "- 시나리오는 다음과 같다.\n",
    "    1. 모델 파일 요청(특정 user, 특정 모델)\n",
    "        - 특정 유저의 token은 어떻게 가지고 있지? 시스템에서 발급을 진행해줘야 하나..\n",
    "        - 유저에게 개인 token 파일을 업로드하라 할까... 우리가 수기로 발급하기에는 많은 어려움이 있어 보인다.\n",
    "    2. 모델 파일 탐색\n",
    "    3. 모델 파일 취약성 점검 여부 확인(protect AI Knowledge Base or Huggingface)\n",
    "    4. token 발급 or 기존 데이터 사용\n",
    "    5. 다운로드 to blob(blob설계 필요. azcopy 특성을 고려한)\n",
    "    6. p-region copy 수행(MSP의 허가가 필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 6 files: 100%|██████████| 6/6 [01:17<00:00, 12.89s/it]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "/api/v1/downloadModel\n",
    "'''\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# token을 사용해서 다운로드 해야하는 경우와, 그렇지 않은 경우가 나뉘는 것으로 보인다.\n",
    "# 이 둘을 구분하여 다운로드 할 수 있도록 해야할 것으로 보인다.\n",
    "\n",
    "# path를 지정하기 위해서는 모델의 확장자를 확인해볼 필요가 있음. safetensors 이외에 다른 확장자(점검이 가능한 확장자)가 있다면 common으로 이동\n",
    "# 아니라면 safetensors 경로로 다운로드\n",
    "# 일단 확장자 검사 로직 패스하고 원하는 경로에 정상적으로 다운로드 되는지 확인\n",
    "\n",
    "# API Body\n",
    "path = \"/Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/common/yolos-tiny\"\n",
    "\n",
    "# 다음과 같은 request가 왔다고 가정.\n",
    "request = {\"user\":3901296\n",
    "           ,\"request_id\":\"request-02\"\n",
    "           ,\"model_name\":\"detr-resnet-50\"\n",
    "           ,\"hugging_face\":True\n",
    "           ,\"repo_id\":\"facebook/detr-resnet-50\"}\n",
    "\n",
    "BASE_PATH = \"/Users/dataeng/modelscan-test/modelscan/unscaned\" # root directory\n",
    "# 나중에 임시 공간에 저장한 다음 이동 시키는 로직을 구성해야할 것 같다. 지금은 일단 이렇게 진행.\n",
    "path = os.path.join(BASE_PATH,str(request['user']),request['request_id'],'model/safetensors',request['model_name'])\n",
    "\n",
    "if request['hugging_face']:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "        model = snapshot_download(repo_id=request['repo_id']\n",
    "                                ,local_dir=path # 모델이 저장될 경로 지정\n",
    "                                # ,allow_patterns=\"\" # 다운로드 받을 패턴 지정\n",
    "                                # ,ignore_patterns=\"\" # 다운로드 시 무시할 패턴 지정\n",
    "                                ) \n",
    "else:\n",
    "    print(\"Pass download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert safetensors -> pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Approach | Popularity | Risk of Model Serialization Attack Exploitability |\n",
    "| --- | --- | --- |\n",
    "| Pickle Variants | Very high | Very high |\n",
    "| Tensorflow SavedModel | High | Medium |\n",
    "| H5 (Keras) | High | Low (except Keras Lambda layer) |\n",
    "| Inference Only | Medium | Low |\n",
    "| Vector/Tensor Only | Low | Very low |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "modelscan module\n",
    "'''\n",
    "\n",
    "class ModelScan():\n",
    "    def __init__(self,base_path:str,model_name:str,ext_in:str,ext_out:str):\n",
    "        self.base_path:str = base_path\n",
    "        self.model_name:str = model_name\n",
    "        self.ext_in:str = ext_in\n",
    "        self.ext_out:str = ext_out\n",
    "        self.tensors:dict = {}\n",
    "\n",
    "    def __check_folder_exists(self,path:str)-> None:\n",
    "        '''\n",
    "        Checking folder is exists. If folder is not exists, then create folder.\n",
    "        '''\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Not existst model folder in {self.ext_out} : {path}\")\n",
    "            os.makedirs(path)\n",
    "        else:\n",
    "            print(\"Exists folder\")\n",
    "\n",
    "    def __model_file_list(self,isLoad=True) -> list:\n",
    "        '''\n",
    "        load model file list\n",
    "        '''\n",
    "        model_weight_file_list = None\n",
    "\n",
    "        # true -> load, false -> store\n",
    "        extension = self.ext_in if isLoad else self.ext_out\n",
    "\n",
    "        model_file_list = os.listdir(os.path.join(self.base_path,extension,self.model_name))\n",
    "        model_weight_file_list = [fn for fn in model_file_list if fn.endswith('.'+extension) and not 'consolidated' in fn]\n",
    "    \n",
    "        return model_weight_file_list\n",
    "    \n",
    "    def __load_model(self,path:str):\n",
    "        '''\n",
    "        다양한 extension input을 지원할 수 있도록 해야함.\n",
    "        '''\n",
    "        tensor = None\n",
    "\n",
    "        if self.ext_in == 'safetensors':\n",
    "            print(\"execute load_file\")\n",
    "            tensor = load_file(path)\n",
    "        elif self.ext_in == 'bin':\n",
    "            print(\"execute load_file\")\n",
    "            tensor = load_file(path)\n",
    "        \n",
    "        return tensor\n",
    "    \n",
    "    def __store_model(self,path:str,model_name:str,tensors=None):\n",
    "        '''\n",
    "        tensor는 어떤 library를 사용하여 load 하는지에 따라 형식이 달라질 수 있다.\n",
    "        추후 다양한 type을 지원할 수 있도록 모듈을 생성해야할 것이다.\n",
    "\n",
    "        1. torch : collections.OrderedDict\n",
    "        '''\n",
    "\n",
    "        self.__check_folder_exists(path=path)\n",
    "        \n",
    "        if self.ext_out == 'pkl':\n",
    "            # pickle을 사용하여 state_dict 저장\n",
    "            store_path = os.path.join(path,model_name+'.'+self.ext_out)\n",
    "            with open(store_path, 'wb') as f:\n",
    "                pickle.dump(tensors, f)\n",
    "        elif self.ext_out == 'npy':\n",
    "            for name, array in tensors.items():\n",
    "                store_path = os.path.join(path,name+'.npy')\n",
    "                np.save(store_path, array)\n",
    "\n",
    "    def __convert(self):\n",
    "        '''\n",
    "        description:\n",
    "            Scaning All Model files(like .safetensor,,)\n",
    "            이 convert 함수를 멀티 thread 혹은 processing으로 구현하면 좋을 것 같은데...\n",
    "        return:\n",
    "\n",
    "        '''\n",
    "        # 1. load model weight with ext_in extension file\n",
    "        load_model_file_list = self.__model_file_list(isLoad=True)\n",
    "        \n",
    "        for f in load_model_file_list:\n",
    "            load_model_file_path = os.path.join(self.base_path,self.ext_in,self.model_name,f)\n",
    "            print(f\"Source Model File Path : {load_model_file_path}\")\n",
    "\n",
    "            # 각 확장자 별로 load함수를 달리 해야한다.\n",
    "            model_weight_file_name = f.split('.')[0]\n",
    "            print(model_weight_file_name)\n",
    "            self.tensors[model_weight_file_name] = self.__load_model(path=load_model_file_path)\n",
    "\n",
    "        # 2. store model weight with ext_out extension file\n",
    "        # .pkl 파일 경로 지정\n",
    "        for i,f in enumerate(load_model_file_list):\n",
    "            store_model_file_name = f.split('.')[0]\n",
    "            store_model_file_path = os.path.join(self.base_path,self.ext_out,self.model_name)\n",
    "            print(f\"Store File Model File Path : {store_model_file_path}\")\n",
    "            self.__store_model(path=store_model_file_path,model_name=store_model_file_name,tensors=self.tensors[store_model_file_name]) \n",
    "    \n",
    "    def scan(self):\n",
    "        # convert\n",
    "        # check해야 할 필요가 없는 파일은 pass 하도록 구현\n",
    "        # convert가 필요한 확장자들을 미리 정의해놓자.\n",
    "        self.__convert()\n",
    "        \n",
    "        # 명령 실행\n",
    "        store_model_folder_path = os.path.join(self.base_path,self.ext_out,self.model_name)\n",
    "\n",
    "        # 검사 결과 저장\n",
    "        report_path = os.path.join(self.base_path.replace(\"unscaned\",\"scaned\"),self.model_name)\n",
    "\n",
    "        # check\n",
    "        self.__check_folder_exists(report_path)\n",
    "\n",
    "        command = f\"modelscan -p {store_model_folder_path} -r json -o {report_path}/{self.model_name}-report.json\"\n",
    "        commands = command.split(\" \")\n",
    "        result = subprocess.run(commands, capture_output=True, text=True)\n",
    "\n",
    "        # 각종 메타 결과는 나중에..\n",
    "        # with open(path,'w') as f:\n",
    "        #     f.write\n",
    "\n",
    "        # 결과 출력\n",
    "        # print(\"Return Code:\", result.returncode)\n",
    "        # print(\"Standard Output:\", result.stdout)\n",
    "        # print(\"Standard Error:\", result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-02/model/safetensors/detr-resnet-50/model.safetensors\n",
      "model\n",
      "execute load_file\n",
      "Store File Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-02/model/npy/detr-resnet-50\n",
      "Not existst model folder in npy : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-02/model/npy/detr-resnet-50\n",
      "Not existst model folder in npy : /Users/dataeng/modelscan-test/modelscan/scaned/3901296/request-02/model/detr-resnet-50\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "/api/v1/modelscan\n",
    "'''\n",
    "\n",
    "BASE_PATH = os.path.join(BASE_PATH,str(request['user']),request['request_id'],'model')\n",
    "\n",
    "ext_in = 'safetensors'\n",
    "ext_out = 'npy'\n",
    "\n",
    "MODEL_NAME=request['model_name']\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    scanner = ModelScan(\n",
    "                base_path=BASE_PATH,\n",
    "                model_name=MODEL_NAME,\n",
    "                ext_in=ext_in,\n",
    "                ext_out=ext_out\n",
    "            )\n",
    "\n",
    "    scanner.scan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelscan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
