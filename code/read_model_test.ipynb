{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Description\n",
    "- 우선 기능 단위로 만들고 하나의 모듈(클래스)로 만들어서 작동시켜보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "from safetensors.torch import load_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert safetensors -> pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"/Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model\"\n",
    "\n",
    "ext_in = 'safetensors'\n",
    "ext_out = 'npy'\n",
    "\n",
    "MODEL_NAME = \"Mistral-Nemo-Instruct-2407\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (120146667.py, line 38)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[47], line 38\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def load_model(ext_in:str,path:str):\n",
    "    tensors = None\n",
    "\n",
    "    if ext_in == 'safetensors':\n",
    "        print(\"execute load_file\")\n",
    "        tensors = load_file(path)\n",
    "    \n",
    "    return tensors\n",
    "\n",
    "def store_model(ext_out:str,path:str,tensors=None):\n",
    "    '''\n",
    "    tensor는 어떤 library를 사용하여 load 하는지에 따라 형식이 달라질 수 있다.\n",
    "    추후 다양한 type을 지원할 수 있도록 모듈을 생성해야할 것이다.\n",
    "\n",
    "    1. torch : collections.OrderedDict\n",
    "    '''\n",
    "    if ext_out == 'pkl':\n",
    "        # pickle을 사용하여 state_dict 저장\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(tensors, f)\n",
    "\n",
    "def convert(base_path:str,model_name:str,file_name:str,ext_in:str, ext_out:str):\n",
    "    # 1. load model weight with ext_in extension file\n",
    "    load_model_file_path = os.path.join(base_path,ext_in,model_name,file_name)\n",
    "    print(f\"Source Model File Path : {load_model_file_path}\")\n",
    "\n",
    "    # 각 확장자 별로 load함수를 달리 해야한다.\n",
    "    tensors = load_model(ext_in=ext_in,path=load_model_file_path)\n",
    "\n",
    "    # 2. store model weight with ext_out extension file\n",
    "    # .pkl 파일 경로 지정\n",
    "    store_model_file_name = '.'.join([file_name.split('.')[0],ext_out])\n",
    "    store_model_file_path = os.path.join(base_path,ext_out,model_name,store_model_file_name)\n",
    "    print(f\"Store File Model File Path : {store_model_file_path}\")\n",
    "    store_model(ext_out=ext_out,path=store_model_file_path,tensors=tensors)  \n",
    "\n",
    "# def model_scan(base_path:str,model_name:str,file_name:str,ext_in:str, ext_out:str):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Approach | Popularity | Risk of Model Serialization Attack Exploitability |\n",
    "| --- | --- | --- |\n",
    "| Pickle Variants | Very high | Very high |\n",
    "| Tensorflow SavedModel | High | Medium |\n",
    "| H5 (Keras) | High | Low (except Keras Lambda layer) |\n",
    "| Inference Only | Medium | Low |\n",
    "| Vector/Tensor Only | Low | Very low |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelScan():\n",
    "    def __init__(self,base_path:str,model_name:str,ext_in:str,ext_out:str):\n",
    "        self.base_path:str = base_path\n",
    "        self.model_name:str = model_name\n",
    "        self.ext_in:str = ext_in\n",
    "        self.ext_out:str = ext_out\n",
    "        self.tensors:dict = {}\n",
    "\n",
    "    def __model_file_list(self,isLoad=True) -> list:\n",
    "        '''\n",
    "        load model file list\n",
    "        '''\n",
    "        model_weight_file_list = None\n",
    "\n",
    "        # true -> load, false -> store\n",
    "        extension = ext_in if isLoad else ext_out\n",
    "\n",
    "        model_file_list = os.listdir(os.path.join(self.base_path,extension,self.model_name))\n",
    "        model_weight_file_list = [fn for fn in model_file_list if fn.endswith('.'+extension) and not 'consolidated' in fn]\n",
    "    \n",
    "        return model_weight_file_list\n",
    "    \n",
    "    def __load_model(self,path:str):\n",
    "        '''\n",
    "        다양한 extension input을 지원할 수 있도록 해야함.\n",
    "        '''\n",
    "        tensor = None\n",
    "\n",
    "        if self.ext_in == 'safetensors':\n",
    "            print(\"execute load_file\")\n",
    "            tensor = load_file(path)\n",
    "        \n",
    "        return tensor\n",
    "    \n",
    "    def __store_model(ext_out:str,path:str,tensors=None):\n",
    "        '''\n",
    "        tensor는 어떤 library를 사용하여 load 하는지에 따라 형식이 달라질 수 있다.\n",
    "        추후 다양한 type을 지원할 수 있도록 모듈을 생성해야할 것이다.\n",
    "\n",
    "        1. torch : collections.OrderedDict\n",
    "        '''\n",
    "        if ext_out == 'pkl':\n",
    "            # pickle을 사용하여 state_dict 저장\n",
    "            with open(path, 'wb') as f:\n",
    "                pickle.dump(tensors, f)\n",
    "        elif ext_out == 'npy':\n",
    "            for name, array in tensors.items():\n",
    "                np.save(f'{name}.npy', array)\n",
    "\n",
    "    def __convert(self):\n",
    "        '''\n",
    "        description:\n",
    "            Scaning All Model files(like .safetensor,,)\n",
    "        return:\n",
    "\n",
    "        '''\n",
    "        # 1. load model weight with ext_in extension file\n",
    "        load_model_file_list = self.__model_file_list(isLoad=True)\n",
    "        for f in load_model_file_list:\n",
    "            load_model_file_path = os.path.join(self.base_path,self.ext_in,self.model_name,f)\n",
    "            print(f\"Source Model File Path : {load_model_file_path}\")\n",
    "\n",
    "            # 각 확장자 별로 load함수를 달리 해야한다.\n",
    "            model_weight_file_name = f.split('.')[0]\n",
    "            self.tensors[model_weight_file_name] = self.__load_model(ext_in=ext_in,path=load_model_file_path)\n",
    "\n",
    "        # 2. store model weight with ext_out extension file\n",
    "        # .pkl 파일 경로 지정\n",
    "        for i,f in enumerate(load_model_file_list):\n",
    "            store_model_file_name = '.'.join([f.split('.')[0],self.ext_out])\n",
    "            store_model_file_path = os.path.join(self.base_path,ext_out,self.model_ame,store_model_file_name)\n",
    "            print(f\"Store File Model File Path : {store_model_file_path}\")\n",
    "            self.__store_model(ext_out=ext_out,path=store_model_file_path,tensors=self.tensors[store_model_file_name]) \n",
    "    \n",
    "    def scan(self):\n",
    "        # convert\n",
    "        # check해야 할 필요가 없는 파일은 pass 하도록 구현\n",
    "        # convert가 필요한 확장자들을 미리 정의해놓자.\n",
    "        self.__convert()\n",
    "        \n",
    "        # 명령 실행\n",
    "        store_model_folder_path = os.path.join(self.base_path,ext_out,self.model_name)\n",
    "\n",
    "        command = f\"modelscan -p {store_model_folder_path} -r json -o output-file-name.json\"\n",
    "        commands = command.split(\" \")\n",
    "        result = subprocess.run(commands, capture_output=True, text=True)\n",
    "\n",
    "        # 결과 출력\n",
    "        print(\"Return Code:\", result.returncode)\n",
    "        print(\"Standard Output:\", result.stdout)\n",
    "        print(\"Standard Error:\", result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/safetensors/Mistral-Nemo-Instruct-2407/model-00003-of-00005.safetensors\n",
      "execute load_file\n",
      "Store File Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/pkl/Mistral-Nemo-Instruct-2407/model-00003-of-00005.pkl\n",
      "Source Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/safetensors/Mistral-Nemo-Instruct-2407/model-00002-of-00005.safetensors\n",
      "execute load_file\n",
      "Store File Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/pkl/Mistral-Nemo-Instruct-2407/model-00002-of-00005.pkl\n",
      "Source Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/safetensors/Mistral-Nemo-Instruct-2407/model-00001-of-00005.safetensors\n",
      "execute load_file\n",
      "Store File Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/pkl/Mistral-Nemo-Instruct-2407/model-00001-of-00005.pkl\n",
      "Source Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/safetensors/Mistral-Nemo-Instruct-2407/model-00004-of-00005.safetensors\n",
      "execute load_file\n",
      "Store File Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/pkl/Mistral-Nemo-Instruct-2407/model-00004-of-00005.pkl\n",
      "Source Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/safetensors/Mistral-Nemo-Instruct-2407/model-00005-of-00005.safetensors\n",
      "execute load_file\n",
      "Store File Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/pkl/Mistral-Nemo-Instruct-2407/model-00005-of-00005.pkl\n"
     ]
    }
   ],
   "source": [
    "model_file_list = os.listdir(os.path.join(BASE_PATH,ext_in,MODEL_NAME))\n",
    "model_weight_file_list = [fn for fn in model_file_list if fn.endswith('.safetensors') and not 'consolidated' in fn]\n",
    "\n",
    "for weight in model_weight_file_list:\n",
    "    convert(base_path=BASE_PATH,model_name=MODEL_NAME,file_name=weight,ext_in=ext_in,ext_out=ext_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Model File Path : /Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model/safetensors/Mistral-Nemo-Instruct-2407/model-00003-of-00005.safetensors\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ModelScan.__load_model() got an unexpected keyword argument 'ext_in'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 17\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     10\u001b[0m     scanner \u001b[38;5;241m=\u001b[39m ModelScan(\n\u001b[1;32m     11\u001b[0m                 base_path\u001b[38;5;241m=\u001b[39mBASE_PATH,\n\u001b[1;32m     12\u001b[0m                 model_name\u001b[38;5;241m=\u001b[39mMODEL_NAME,\n\u001b[1;32m     13\u001b[0m                 ext_in\u001b[38;5;241m=\u001b[39mext_in,\n\u001b[1;32m     14\u001b[0m                 ext_out\u001b[38;5;241m=\u001b[39mext_out\n\u001b[1;32m     15\u001b[0m             )\n\u001b[0;32m---> 17\u001b[0m     \u001b[43mscanner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[49], line 79\u001b[0m, in \u001b[0;36mModelScan.scan\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscan\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# convert\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# check해야 할 필요가 없는 파일은 pass 하도록 구현\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# convert가 필요한 확장자들을 미리 정의해놓자.\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# 명령 실행\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     store_model_folder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_path,ext_out,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name)\n",
      "Cell \u001b[0;32mIn[49], line 65\u001b[0m, in \u001b[0;36mModelScan.__convert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# 각 확장자 별로 load함수를 달리 해야한다.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     model_weight_file_name \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors[model_weight_file_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mext_in\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mext_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_model_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# 2. store model weight with ext_out extension file\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# .pkl 파일 경로 지정\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(load_model_file_list):\n",
      "\u001b[0;31mTypeError\u001b[0m: ModelScan.__load_model() got an unexpected keyword argument 'ext_in'"
     ]
    }
   ],
   "source": [
    "BASE_PATH = \"/Users/dataeng/modelscan-test/modelscan/unscaned/3901296/request-01/model\"\n",
    "\n",
    "ext_in = 'safetensors'\n",
    "ext_out = 'npy'\n",
    "\n",
    "MODEL_NAME = \"Mistral-Nemo-Instruct-2407\"\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    scanner = ModelScan(\n",
    "                base_path=BASE_PATH,\n",
    "                model_name=MODEL_NAME,\n",
    "                ext_in=ext_in,\n",
    "                ext_out=ext_out\n",
    "            )\n",
    "\n",
    "    scanner.scan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelscan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
